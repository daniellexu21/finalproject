---
title: "Final Model"
format: 
  pdf:
    geometry: 
      - left=0.8in
      - right=0.8in
      - top=0.8in
      - bottom=0.8in
editor: 
  markdown: 
    wrap: 72
---

```{r, include=FALSE}
library(dplyr)
library(tidyverse)
library(readr)
library(janitor)
library(lubridate)
library(randomForest)
library(gbm)
library(caret)
library(pROC)
library(xgboost)
library(knitr)
library(kableExtra)

```

```{r}
flight_23_full <- readRDS("flight_23_full.rds")
flight_24_full <- readRDS("flight_24_full.rds")
```


```{r}
# Weather delay as response variable
train_weather <- flight_23_full
set.seed(42)  # for reproducibility
n_2024_weather <- nrow(flight_24_full)
test_indices <- sample(1:n_2024_weather, size = 0.3 * n_2024_weather)
test_weather <- flight_24_full[test_indices, ] 

#Factor
train_weather$weather <- factor(train_weather$weather)
test_weather$weather <- factor(test_weather$weather, levels = levels(train_weather$weather))
#Delay for 15 minutes or more as response variable
train_weather$dep_del15 <- factor(train_weather$dep_del15, levels = c(0, 1))
test_weather$dep_del15 <- factor(test_weather$dep_del15, levels = c(0, 1))

rf.fit_weather <- randomForest(weather ~ op_unique_carrier + distance + dep_period + prcp + awnd + tmax + tmin,
                         data = train_weather, 
                         importance = TRUE, 
                         ntree = 500)
rf_preds_weather <- predict(rf.fit_weather, newdata = test_weather, type = "response")

# Confusion matrix to evaluate performance
confusion_matrix <- table(predicted = rf_preds_weather, actual = test_weather$weather)
print(confusion_matrix)
mean(rf_preds_weather == test_weather$weather)
varImpPlot(rf.fit_weather)

#Departure delay > 15 as response

rf.fit.w <- randomForest(dep_del15 ~ op_unique_carrier + distance + dep_period + prcp + awnd + tmax + tmin,
                         data = train_weather, 
                         importance = TRUE, 
                         ntree = 5000)
rf_preds_w <- predict(rf.fit.w, newdata = test_weather, type = "response")


# Confusion matrix to evaluate performance
confusion_matrix <- table(predicted = rf_preds_w, actual = test_weather$dep_del15)
print(confusion_matrix)
mean(rf_preds_w == test_weather$dep_del15)
varImpPlot(rf.fit.w)

vi_rf <- importance(rf.fit.w)
vi_rf_df <- data.frame(
  Variable = rownames(vi_rf),
  Importance = vi_rf[, "MeanDecreaseGini"]
)

# Sort by descending importance
vi_rf_df <- vi_rf_df[order(vi_rf_df$Importance, decreasing = TRUE), ]
ggplot(vi_rf_df, aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  theme_minimal() +
  labs(title = "Random Forest Variable Importance",
       x = "Variable",
       y = "Mean Decrease in Gini") +
  theme(plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12))

```

```{r}

# Prepare your data as a matrix
x_train <- model.matrix(dep_del15 ~ op_unique_carrier + distance + dep_period + prcp + awnd + tmax + tmin, data = train_weather)[, -1]
y_train <- train_weather$dep_del15
x_test <- model.matrix(dep_del15 ~ op_unique_carrier + distance + dep_period + prcp + awnd + tmax + tmin, data = test_weather)[, -1]
y_test <- test_weather$dep_del15  
#Improve random forest using cross validation
control <- trainControl(
  method = "cv",
  number = 5,
  classProbs = TRUE,
  summaryFunction = twoClassSummary
)

# Convert target to "Yes"/"No" if needed for twoClassSummary
y_train_factor <- ifelse(y_train == 1, "Yes", "No")

tunegrid <- expand.grid(.mtry = c(2, 4, 6, 8))

rf_cv_auc <- train(
  x = x_train,
  y = as.factor(y_train_factor),
  method = "rf",
  trControl = control,
  tuneGrid = tunegrid,
  metric = "ROC",
  ntree = 500
)
rf_cv_auc$bestTune

# View AUC for each mtry
rf_cv_auc$results[, c("mtry", "ROC")]
# Get best mtry from cross-validated model
best_mtry <- rf_cv_auc$bestTune$mtry

# Refit Random Forest on the full training data
rf.fit.w <- randomForest(
  x = x_train,
  y = as.factor(y_train_factor),  # Use original binary factor: "Yes"/"No"
  mtry = best_mtry,
  ntree = 500
)

# Convert y_test to factor ("Yes"/"No")
y_test_factor <- ifelse(y_test == 1, "Yes", "No")

# Predict probabilities for ROC/AUC
rf_probs <- predict(rf.fit.w, newdata = x_test, type = "prob")[, "Yes"]

# Predict classes
rf_preds <- predict(rf.fit.w, newdata = x_test)

# Confusion matrix
conf_mat <- confusionMatrix(rf_preds, as.factor(y_test_factor))
conf_mat
accuracy <- conf_mat$overall['Accuracy']
accuracy

# AUC
library(pROC)
rf_auc <- roc(y_test_factor, rf_probs)
rf_auc$auc

# Extract variable importance
var_imp <- importance(rf.fit.w, type = 2)  # type = 2 for MeanDecreaseGini
var_imp_df <- data.frame(Variable = rownames(var_imp), Importance = var_imp[, 1])

# Order by importance
var_imp_df <- var_imp_df[order(var_imp_df$Importance, decreasing = TRUE), ]

# Create a pretty plot
rf_imp_plot <- ggplot(var_imp_df, aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(
    title = "Variable Importance (Random Forest)",
    x = "Variables",
    y = "Mean Decrease in Gini"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        strip.text = element_text(size = 14),
        axis.text = element_text(size = 12),
        axis.title = element_text(size = 13))
rf_imp_plot
ggsave("variable_importance_rf.jpg", plot = rf_imp_plot, width = 8, height = 6, dpi = 300)

```

```{r}
train_weather <- flight_23_full
set.seed(42)  # for reproducibility
n_2024_weather <- nrow(flight_24_full)
test_indices <- sample(1:n_2024_weather, size = 0.3 * n_2024_weather)
test_weather <- flight_24_full[test_indices, ] 

train_weather$op_unique_carrier <- as.factor(train_weather$op_unique_carrier)
train_weather$dep_period <- as.factor(train_weather$dep_period)

test_weather$op_unique_carrier <- factor(test_weather$op_unique_carrier, levels = levels(train_weather$op_unique_carrier))
test_weather$dep_period <- factor(test_weather$dep_period, levels = levels(train_weather$dep_period))


#Boosting

#Refit with cross validation
boost.fit <- gbm(dep_del15 ~ op_unique_carrier + distance + dep_period + prcp + awnd + tmax + tmin,
                 data = train_weather, 
                 distribution = "bernoulli",
                 n.trees = 5000, 
                 interaction.depth = 3, 
                 shrinkage = 0.01,
                 cv.folds = 5,        # Add cross-validation!
                 n.cores = NULL,       # Use all cores
                 verbose = FALSE)
best.iter <- gbm.perf(boost.fit, method = "cv") #Optimal number of trees ~ 1800
yhat.boost <- predict(boost.fit, newdata = test_weather, n.trees = best.iter, type = "response")
yhat.boost.class <- ifelse(yhat.boost > 0.5, 1, 0)
mean(yhat.boost.class == test_weather$dep_del15)

table(yhat.boost.class)
vi_boost <- summary(boost.fit, n.trees = best.iter, plotit = FALSE)

# It already returns a data.frame with columns 'var' and 'rel.inf'
# Rename columns for clarity
colnames(vi_boost) <- c("Variable", "Importance")

# Sort descending
vi_boost <- vi_boost[order(vi_boost$Importance, decreasing = TRUE), ]
ggplot(vi_boost, aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "coral") +
  coord_flip() +
  theme_minimal() +
  labs(title = "Boosting Variable Importance",
       x = "Variable",
       y = "Relative Influence (%)") +
  theme(plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12))




```

```{r}
# Prepare your data as a matrix
x_train <- model.matrix(dep_del15 ~ op_unique_carrier + distance + dep_period + prcp + awnd + tmax + tmin, data = train_weather)[, -1]
y_train <- train_weather$dep_del15
x_test <- model.matrix(dep_del15 ~ op_unique_carrier + distance + dep_period + prcp + awnd + tmax + tmin, data = test_weather)[, -1]
y_test <- test_weather$dep_del15  

xgb.fit <- xgboost(data = x_train, label = y_train,
                   nrounds = 1000, objective = "reg:squarederror",
                   max_depth = 4, eta = 0.1, early_stopping_rounds = 10,
                   verbose = 0)
# Get feature names from matrix
feature_names <- colnames(x_train)

# Extract importance
xgb.imp <- xgb.importance(feature_names = feature_names, model = xgb.fit)
head(xgb.imp)
xgb.plot.importance(xgb.imp, top_n = 20, measure = "Gain",
                    rel_to_first = TRUE, xlab = "Relative Importance")

#Improve using CV
cv_results <- xgb.cv(
  data = x_train, 
  label = y_train, 
  nrounds = 1000,             # Number of boosting rounds
  objective = "binary:logistic",  # Binary classification task
  max_depth = 4,              # Depth of trees
  eta = 0.1,                  # Learning rate
  early_stopping_rounds = 10, # Stop if no improvement in 10 rounds
  nfold = 5,                 # 5-fold cross-validation
  verbose = 0,                # Disable verbose output
  metric = "auc"              # Optimize for AUC
)
cat("Best AUC:", min(cv_results$evaluation_log$test_auc_mean), "\n")
cat("Best number of rounds:", cv_results$best_iteration, "\n")

# Train the final model with the best number of rounds
xgb.fit <- xgboost(
  data = x_train, 
  label = y_train, 
  nrounds = cv_results$best_iteration,
  objective = "binary:logistic",
  max_depth = 4, 
  eta = 0.1, 
  verbose = 0
)
feature_names <- colnames(x_train)
# Extract importance
xgb.imp <- xgb.importance(feature_names = feature_names, model = xgb.fit)
head(xgb.imp)
xgb.plot.importance(xgb.imp, top_n = 20, measure = "Gain",
                    rel_to_first = TRUE, xlab = "Relative Importance")
```

```{r}
# GBM variable importance (already extracted)
vi_gbm <- summary(boost.fit, n.trees = best.iter, plotit = FALSE)
colnames(vi_gbm) <- c("Variable", "Importance")
vi_gbm$Model <- "GBM"
# Assuming xgb.fit and x_train already created
xgb_imp <- xgb.importance(feature_names = colnames(x_train), model = xgb.fit)
vi_xgb <- xgb_imp[, c("Feature", "Gain")]
colnames(vi_xgb) <- c("Variable", "Importance")
vi_xgb$Model <- "XGBoost"

# Normalize each model's importance (optional but helps visually)
vi_all <- bind_rows(vi_gbm, vi_xgb) %>%
  group_by(Model) %>%
  mutate(Importance = Importance / max(Importance) * 100) %>%
  ungroup()

# Top 10 variables per model
top_vars <- vi_all %>%
  group_by(Model) %>%
  top_n(10, Importance)

boost_compare_plot <- ggplot(top_vars, aes(x = reorder(Variable, Importance), y = Importance, fill = Model)) +
  geom_col(show.legend = FALSE) +
  coord_flip() +
  facet_wrap(~Model, scales = "free_y") +
  theme_minimal() +
  labs(title = "Variable Importance: GBM vs. XGBoost",
       x = "Variable",
       y = "Relative Importance (%)") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        strip.text = element_text(size = 14),
        axis.text = element_text(size = 12),
        axis.title = element_text(size = 13))
boost_compare_plot
ggsave("variable_importance_boost.png", plot = boost_compare_plot, width = 8, height = 6, dpi = 300)


```

```{r}


# Predictions (raw probabilities)
prob_gbm <- predict(boost.fit, newdata = test_weather, n.trees = best.iter, type = "response")
prob_xgb <- predict(xgb.fit, newdata = x_test)


# Convert probabilities to class predictions (threshold = 0.5)
pred_gbm <- ifelse(prob_gbm > 0.5, 1, 0)
pred_xgb <- ifelse(prob_xgb > 0.5, 1, 0)
pred_rf  <- ifelse(rf_probs  > 0.5, 1, 0)

# Confusion matrix & Accuracy
cm_gbm <- confusionMatrix(factor(pred_gbm), factor(y_test))
cm_xgb <- confusionMatrix(factor(pred_xgb), factor(y_test))
cm_rf <- confusionMatrix(factor(pred_rf),  factor(y_test))
cm_gbm
# AUC
auc_gbm <- roc(y_test, prob_gbm)$auc
auc_xgb <- roc(y_test, prob_xgb)$auc
auc_rf  <- roc(y_test, rf_probs)$auc

#Accuracy
accuracy_gbm <- cm_gbm$overall["Accuracy"]
accuracy_xgb <- cm_xgb$overall["Accuracy"]
accuracy_rf <- cm_rf$overall["Accuracy"]
# Summary
data.frame(Model = c("GBM", "XGBoost", "Random Forest"),
           AUC   = c(auc_gbm, auc_xgb, auc_rf),
           Accuracy = c(accuracy_gbm, accuracy_xgb, accuracy_rf))

```

```{r}
stats.table <- data.frame(
  Model = c("GBM", "XGBoost", "Random Forest"),
  AUC = c(auc_gbm, auc_xgb, auc_rf),
  Accuracy = c(accuracy_gbm, accuracy_xgb, accuracy_rf)
)
summary_table <- stats.table |> 
  kbl(
    caption = "Model Performance Comparison: AUC and Accuracy",
    col.names = c("Model", "AUC", "Accuracy"),
    align = "c", 
    booktabs = TRUE,
    linesep = ""
  ) |> 
  kable_classic(full_width = FALSE, latex_options = c("HOLD_position"))

summary_table

```
